#!/usr/bin/env python3
"""Test all service connections before running ingestion.

Usage:
    cd backend
    python -m scripts.test_connections
"""

import asyncio
import sys
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from config import get_settings
from services import embedding, llm, vector_store, database


async def test_voyage_ai() -> bool:
    """Test Voyage AI embedding service."""
    print("\nğŸ“¦ Testing Voyage AI (embeddings)...")
    try:
        result = await embedding.check_connection()
        if result["status"] == "healthy":
            print(f"   âœ… Connected to Voyage AI")
            print(f"   Model: {result['model']}")
            print(f"   Dimensions: {result['dimensions']}")
            return True
        else:
            print(f"   âŒ Voyage AI unhealthy: {result.get('error', 'Unknown error')}")
            return False
    except Exception as e:
        print(f"   âŒ Voyage AI error: {e}")
        return False


async def test_groq() -> bool:
    """Test Groq LLM service."""
    print("\nğŸ¤– Testing Groq (LLM)...")
    try:
        result = await llm.check_connection()
        if result["status"] == "healthy":
            print(f"   âœ… Connected to Groq")
            print(f"   Model: {result['model']}")
            return True
        else:
            print(f"   âŒ Groq unhealthy: {result.get('error', 'Unknown error')}")
            return False
    except Exception as e:
        print(f"   âŒ Groq error: {e}")
        return False


async def test_qdrant() -> bool:
    """Test Qdrant vector store connection."""
    print("\nğŸ” Testing Qdrant (vector store)...")
    try:
        # First initialize the collection if needed
        await vector_store.init_collection()

        result = await vector_store.check_connection()
        if result["status"] == "healthy":
            print(f"   âœ… Connected to Qdrant")
            print(f"   Collection: {result['collection']}")
            print(f"   Vectors: {result.get('vectors_count', 0)}")
            return True
        else:
            print(f"   âŒ Qdrant unhealthy: {result.get('error', 'Unknown error')}")
            return False
    except Exception as e:
        print(f"   âŒ Qdrant error: {e}")
        return False


async def test_neon() -> bool:
    """Test Neon Postgres database connection."""
    print("\nğŸ˜ Testing Neon Postgres (database)...")
    try:
        # Initialize schema first (creates tables if not exist)
        await database.init_schema()
        print("   âœ… Schema initialized")

        result = await database.check_connection()
        if result["status"] == "healthy":
            print(f"   âœ… Connected to Neon Postgres")
            print(f"   Version: {result.get('version', 'Unknown')}")
            return True
        else:
            print(f"   âŒ Neon unhealthy: {result.get('error', 'Unknown error')}")
            return False
    except Exception as e:
        print(f"   âŒ Neon error: {e}")
        return False


async def test_full_pipeline() -> bool:
    """Test full RAG pipeline with a sample query."""
    print("\nğŸ”„ Testing full RAG pipeline...")
    try:
        # Generate a test embedding
        test_query = "What is a humanoid robot?"
        query_embedding = await embedding.embed_text(test_query, input_type="query")
        print(f"   âœ… Generated query embedding ({len(query_embedding)} dims)")

        # Try a vector search (may return empty if no data)
        settings = get_settings()
        results = await vector_store.search_similar_chunks(
            query_embedding=query_embedding,
            top_k=3,
            score_threshold=0.5,
        )
        print(f"   âœ… Vector search returned {len(results)} results")

        # Test LLM with a simple prompt (no context needed)
        test_messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Say 'Hello from Groq!' in exactly 5 words."}
        ]
        response = await llm.generate_response_groq(test_messages)
        print(f"   âœ… LLM response: {response[:50]}...")

        return True
    except Exception as e:
        print(f"   âŒ Pipeline error: {e}")
        return False


async def main():
    """Run all connection tests."""
    print("=" * 60)
    print("ğŸ§ª RAG Chatbot Connection Tests")
    print("=" * 60)

    settings = get_settings()
    print(f"\nConfiguration loaded:")
    print(f"  - Voyage model: {settings.voyage_embedding_model}")
    print(f"  - Groq model: {settings.groq_llm_model}")
    print(f"  - Qdrant collection: {settings.qdrant_collection_name}")

    results = {
        "Voyage AI": await test_voyage_ai(),
        "Groq": await test_groq(),
        "Qdrant": await test_qdrant(),
        "Neon Postgres": await test_neon(),
    }

    # Only test pipeline if all services are healthy
    if all(results.values()):
        results["Full Pipeline"] = await test_full_pipeline()

    print("\n" + "=" * 60)
    print("ğŸ“Š Test Results Summary")
    print("=" * 60)

    all_passed = True
    for service, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"  {service}: {status}")
        if not passed:
            all_passed = False

    print("\n" + "=" * 60)
    if all_passed:
        print("ğŸ‰ All tests passed! Ready for content ingestion.")
        print("   Run: python -m scripts.ingest_content")
    else:
        print("âš ï¸  Some tests failed. Check configuration and try again.")
    print("=" * 60)

    return 0 if all_passed else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
